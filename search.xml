<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[HTTPs证书相关]]></title>
    <url>%2F2018%2F03%2F25%2FHTTPS-certificate%2F</url>
    <content type="text"><![CDATA[去年某客户需要使用HTTP/2业务来做人工直播内容审核用。具体操作应该为一个大屏幕，一个chrome浏览器，浏览器使用HTTP/2可以复用一个连接，向节点同时请求几十路流，随后进行审核。 由于彼时公司所使用的cache软件和前端反向代理软件均不支持HTTP/2，所以在客户要求的区域，搭建了两台NGINX服务的机器，由客户使用hosts访问的形式进行服务。 近期该客户所使用的证书过期，而由于该两台机器为人工配置，未自动更新新的证书，导致该服务异常。而客服人员所提供的新的证书没有包含私钥，导致证书一度无法更新。 之前对于HTTPs业务一直未有真的接触，此次趁机学习一记。 加密方式与应用对称加密对称加密的主要原理是，数据交互双方使用事先通过一定途径约定好的秘钥对需要传输的消息进行加密，并使用同样的秘钥对收到的加密消息进行解密。 由于使用的加解密的秘钥一样，所以称为对称加密。常见的对称加密方式有DES、3DES、TDEA、Blowfish、RC2、RC4、RC5、IDEA、SKIPJACK、AES等。 非对称加密非对称加密区别于对称加密的一点是，数据交互双方持有的秘钥不一样，一般用户持有的秘钥称为公钥，而服务端持有的秘钥为私钥。公钥可以公开，服务端对于任何请求方都可以响应其公钥。而私钥只能是服务端持有。 当需要进行加密通信时，服务端将公钥提供给用户并携带一个随机数，用户利用公钥和随机数将需要传输的消息加密。服务端通过私钥解密，得到明文消息。 服务端对需要响应的消息利用hash算法生成摘要，并利用私钥将摘要加密，形成数字签名。当客户端收到响应后，利用公钥解开数字签名，得到摘要，然后对收到的消息利用同样的hash算法生成摘要，对比两者摘要是否相同。如果相同，则认为响应消息来自指定服务端。 常见的非对称加密有：RSA、Elgamal、背包算法、Rabin、D-H、ECC（椭圆曲线加密算法）。 实际应用非对称加解密的计算消耗要比对称加解密大很多，所以实际应用一般采用两者的结合达到速度和安全的两全其美。即：使用非对称机密方式传输对称加密的秘钥。用对称加密传输实际的消息。 CA, certificate authority剩下的问题是如何在在非对称加密时，把服务器的公钥传输给请求方了。若是直接传输，公钥在传输过程如果发生劫持被替换成其他公钥怎么办。 以上问题总结下来便是如何证明收到的公钥便是便是实际请求响应方给的呢。 此处引入一个数字摘要的概念。消息摘要是将公钥和其他证书申请者的信息作为hash输入（预映射）而得到的hash值。由于hash唯一性，如果中途被篡改，则相应的消息摘要将发生变化，无法校验通过。 为了防止中间劫持方修改整个公钥和其他预映射的信息，并生成新的消息摘要，服务端在提供消息摘要时，会使用有权威性的证书授权中心的私钥进行加密，而这些权威性的证书授权中心的公钥则预设在我们的操作系统或者浏览器中。当中途证书被劫持篡改后，将无法校验通过。 上述权威性的证书授权中心即所谓的CA,certificate authority，比较著名的有Symantec，GeoTrust和新兴的免费的Let’s Encrypt等。 HTTPS交互使用cURL发起一次HTTPS的请求，cURL记录的响应如下： /usr/local/curl-7.55.1/bin/curl --http2 --cacert /etc/pki/tls/certs/ca-bundle.crt https://pull-flv-l1-hs-admin.pstatp.com/live/livestream.flv -v * Trying 110.242.21.20... * TCP_NODELAY set * Connected to pull-flv-l1-hs-admin.pstatp.com (110.242.21.20) port 443 (#0) * ALPN, offering h2 * ALPN, offering http/1.1 * Cipher selection: ALL:!EXPORT:!EXPORT40:!EXPORT56:!aNULL:!LOW:!RC4:@STRENGTH * successfully set certificate verify locations: * CAfile: /etc/pki/tls/certs/ca-bundle.crt CApath: none * TLSv1.2 (OUT), TLS header, Certificate Status (22): * TLSv1.2 (OUT), TLS handshake, Client hello (1): * TLSv1.2 (IN), TLS handshake, Server hello (2): * TLSv1.2 (IN), TLS handshake, Certificate (11): * TLSv1.2 (IN), TLS handshake, Server key exchange (12): * TLSv1.2 (IN), TLS handshake, Server finished (14): * TLSv1.2 (OUT), TLS handshake, Client key exchange (16): * TLSv1.2 (OUT), TLS change cipher, Client hello (1): * TLSv1.2 (OUT), TLS handshake, Finished (20): * TLSv1.2 (IN), TLS change cipher, Client hello (1): * TLSv1.2 (IN), TLS handshake, Finished (20): * SSL connection using TLSv1.2 / ECDHE-RSA-AES128-GCM-SHA256 * ALPN, server accepted to use h2 * Server certificate: * subject: CN=*.pstatp.com * start date: Dec 21 00:00:00 2017 GMT * expire date: Dec 26 12:00:00 2020 GMT * subjectAltName: host "pull-flv-l1-hs-admin.pstatp.com" matched cert's "*.pstatp.com" * issuer: C=US; O=DigiCert Inc; OU=www.digicert.com; CN=RapidSSL RSA CA 2018 * SSL certificate verify ok. * Using HTTP2, server supports multi-use * Connection state changed (HTTP/2 confirmed) * Copying HTTP/2 data in stream buffer to connection buffer after upgrade: len=0 * Using Stream ID: 1 (easy handle 0x10cc020) > GET /live/livestream.flv HTTP/2 > Host: pull-flv-l1-hs-admin.pstatp.com > User-Agent: curl/7.55.1 > Accept: */* > * Connection state changed (MAX_CONCURRENT_STREAMS updated)! &lt; HTTP/2 200 &lt; date: Sun, 25 Mar 2018 03:08:54 GMT &lt; content-type: video/x-flv &lt; cache-control: no-cache &lt; expires: -1 &lt; pragma: no-cache &lt; Warning: Binary output can mess up your terminal. Use "--output -" to tell Warning: curl to output it to your terminal anyway, or consider "--output Warning: &lt;FILE>" to save to a file. * Failed writing body (0 != 13) * Closing connection 0 * TLSv1.2 (OUT), TLS alert, Client hello (1): 可以看到cURL在tcp建联后，进入了TLSv1.2的SSL层数据交互。 首先Client端发起Client Hello，会提供4字节的unix时间和用于后续使用的28字节随机数random_C。并且会携带客户端支持所有加密套件(Cipher Suites)名称，以供服务器选择，如下图一所示。 图一 并且可能会在扩展信息(Extension)中携带请求URL的server name信息，方便服务器决定使用哪本SNI证书。关于SNI证书，可以查看维基百科。请求如下图二所示。 图二 服务端收到Client Hello后会相应响应给客户端Server Hello，会提供服务端的4字节的unix时间和用于后续使用的28字节随机数random_S，并且选定客户端提供的支持的加密套件中的一种，如下图三中所示，选择是**TLS_ECDHE_RSA_WITH_AES_128_GCM_SHA256**，其具体的含义为： 基于TLS协议； 使用ECDHE作为秘钥交换算法； RSA作为签名认证； AES_128_GCM作为对称加密算法； SHA256作为摘要算法； 再深入的信息，估计是要看几本大部头的书才能理解了。 图三 服务端在发送Server Hello之后，便会将相关的证书（包含公钥）发送给客户端，该操作称为Certificate，如下图四所示，其中包含的证书信息如下图五所示。 图四 图五 此次加密通信中，使用的是ECDHE算法作为秘钥交换算法。所以服务端在发送Certificate消息后还会给出用于ECDHE加密使用的信息，称作Server Key Exchange。如下图六，服务端提供了加密算法所需的Pubkey以及对数据做了一次签名。 图六 到此，服务端所需传递的数据均已完成，服务端发送一个Server Hello done消息，表示完成。如下图七。 图七 接下来轮到客户端表演了。在收到服务端的Server Key Exchange之后，客户端会进行秘钥交换，做相应的Client Key Exchange动作，交换一些加密参数。如下图八。 此时，不出意外，服务端和客户端就可以进行加密通信了。客户端发送ChangeCipher Spec消息，表示接下来开始加密通信，随后发送一个加密的握手消息Encrypted Handshake Message进行验证。如下图八。 图八 服务端收到客户端开始加密通信的消息和加密的握手消息后，相应的也响应一个开始加密通信的消息Change Cipher Spec，并且也发送一个加密的握手消息Encrypted Handshake Message。如图十所示。 图九 至此，加密通道完成建立，开始进行加密通信。直到客户端发起Encrypted Alert，表示结束为止。 总结下来的流程图大致如此： 详细的加密算法基本也不用了解。太高深了。 NGINX证书配置NGINX作为proxy使用时的相关配置。 对外域名为pull.test.com，启用HTTP和HTTPS，并且启用HTTP2， server { server_name pull.test.com; listen [::]:443 ssl http2 reuseport; listen [::]:80 http2 reuseport; ssl_certificate /SSL_cert/test.com.crt; ssl_certificate_key /SSL_cert/test.com.key; ssl_trusted_certificate /SSL_cert/test.com.ca; ssl_ciphers ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES256-GCM-SHA384:ECDHE-ECDSA-AES256-GCM-SHA384:DHE-RSA-AES128-GCM-SHA256:DHE-DSS-AES128-GCM-SHA256:kEDH+AESGCM:ECDHE-RSA-AES128-SHA256:ECDHE-ECDSA-AES128-SHA256:ECDHE-RSA-AES128-SHA:ECDHE-ECDSA-AES128-SHA:ECDHE-RSA-AES256-SHA384:ECDHE-ECDSA-AES256-SHA384:ECDHE-RSA-AES256-SHA:ECDHE-ECDSA-AES256-SHA:DHE-RSA-AES128-SHA256:DHE-RSA-AES128-SHA:DHE-DSS-AES128-SHA256:DHE-RSA-AES256-SHA256:DHE-DSS-AES256-SHA:DHE-RSA-AES256-SHA:!aNULL:!eNULL:!EXPORT:!DES:!RC4:!3DES:!MD5:!PSK; location / { set $s_host ori.pull.test.com; proxy_set_header Host $s_host; more_set_headers "Access-Control-Allow-Origin:*"; proxy_pass http://127.0.0.1:xxx; } //test URL location = /live/livestream.flv { set $s_host test.test.com; proxy_set_header Host $s_host;d proxy_pass http://127.0.0.1:xxx; } } Client->Server: Client Hello Server->Client: Server Hello Server->Client: Certificate Server->Client: Server Key Exchange Server->Client: Server Hello Done Client->Server: Client Key Exchange Client->Server: Change Cipher Spec Client->Server: Encrypted Handshake Message Server->Client: Change Cipher Spec Server->Client: Encrypted Handshake Message Client->Server: Application Data Server->Client: Application Data Client-->Server: ... Server-->Client: ... Client->Server: Encrypted Alert{"scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12,"theme":"simple"} var code = document.getElementById("sequence-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("sequence-0-options").value)); var diagram = Diagram.parse(code); diagram.drawSVG("sequence-0", options);]]></content>
      <tags>
        <tag>HTTPS</tag>
        <tag>NGINX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[H265码流格式]]></title>
    <url>%2F2018%2F02%2F04%2FH265_format%2F</url>
    <content type="text"><![CDATA[H265标准自2013年推出以来，一直受限于CPU或者GPU硬解性能的限制，难以普及。 IOS11的VideoToolbox支持硬解H265，开发者可以调用提供的接口实现HEVC的硬解。而安卓阵营近几代SOC芯片早就支持了H265的硬解，并且其计算能力也强大到出现了出现了讨论是否性能过剩的现象。至于PC端，由于PC设备更新速度远没有移动设备快速，目前在用的PC设备性能参差不齐，并且这类现象会持续一长段时间。 推流侧的H265比拉流要容易推广，主播向来持有的设备性能都较强，也是比较新的旗舰产品，一般都可以支持HEVC的硬编。 在CDN侧，各大CDN服务提供商大多数均已支持了H265格式的视频数据分发。 基于以上，预测2018年，各大视频内容提供商处于CDN带宽成本考虑，应该会把H265作为一个比较重要的工作项目。 所以，我们学习下H265的码流格式。 FLV与H265FLV是一个Adobe公司为flash播放器(SWF)配套推出的视频封装格式。由于其格式结构简单，配套方案成熟，在流媒体行业内应用十分广泛。 虽然FLV的标准几乎每年都在更新，但是Adobe并没有让FLV支持H265。FLV支持的编码格式有以下几种（引自wikipedia）： Id Video encoding 0 RGB 1 run-length 2 Sorenson’s H.263 3 Screen 1 4 On2 TrueMotion VP6 5 VP6 with alpha 6 Screen 2 7 MP4 H.264 8 ITU H.263 9 MPEG-4 ASP. 目前国内直播大多数采用HTTP-FLV的拉流方式，其原因是HTTP可以保证在TCP握手成功之后马上发起GET请求，不像RTMP那样还需要进行RTMP应用层面的握手以及各类message消息的传输来确定许多参数，从而保证较快的首屏时间。至于HLS，HDS，MSS，MPEG-DASH等基于切片的，在国外直播中较为常见，国内的直播普遍无法接受切片带来的延迟，因此HTTP-FLV在国内直播行业内应用广泛。 理所当然的，大家也都希望将H265的码流也封装进FLV中，如此可以省去很多适配工作。 因此，便有了非官方的墨守成规的”标准“了。 FLV中，Video Tag中的Tag Data中的第一字节的低四位表示编码格式CodecID，其取值便如上述表格所示，常见的是7，即AVC编码方式。而非官方的大家普遍的做法是将0XC=12D标志为HEVC。 H265码流格式2018年2月6日补充，在非官方的FLV封装265码流中，基本与264一致，分为265标准自带的附录B（Annex-B）和avcC类似的hvcC。 hvcC一般解析 2C 2，代表非关键帧 CH=12D，代表CodecID=12D，为hevc 01 沿用AVC中的格式 00 00 00 沿用AVC中的格式 00 00 15 B0 代表下一个NALU的长度为15B0H=5552D字节 02 01H=0000 0010 0000 0001B，NAL units header 第一位，1比特，0，禁止位，forbidden_zero_bit。非零代表异常； 第二至七位，6比特，000001，NALU类型，nal_unit_type。常见的类型有： 40 01H–&gt;nal_unit_type=32D，VPS 42 01H–&gt;nal_unit_type=33D，SPS 44 01H–&gt;nal_unit_type=34D，PPS 4E 01H–&gt;nal_unit_type=39D，SEI 26 01H–&gt;nal_unit_type=19D，IDR 02 01H–&gt;nal_unit_type=1D，被参考的后置图像 第八至十三位，6比特，000000，nuh_layer_id，一般取值为0，非0为3D等特殊视频。 第十四至十六位，3比特，001，nuh_temporal_id_plus1，NALU所在时域层的标识号temporalId+1。 hvcC头解析 1C 1，代表关键帧 CH=12D，代表CodecID=12D，为hevc 01 沿用AVC中的格式 00 00 00 沿用AVC中的格式 00 00 00 19 下一个NALU的长度为19H字节 40 01 0C 01 … 40 01 : VPS 00 00 00 28 下一个NALU的长度为28H字节 42 01 01 01 … 42 01 : SPS 00 00 00 08 下一个NALU的长度为8H字节 44 01 C1 71 … 44 01 : PPS 00 03 A0 C1 下一个NALU的长度是03A0C1H字节 26 01 .. 26 01 : IDR Annex-B一般解析 1C 1，代表关键帧 CH=12D，代表CodecID=12D，为hevc 01 沿用AVC中的格式 00 01 F4 沿用AVC中的格式 00 00 00 01 Start code : 分隔符 26 01 … 26 01 : IDR 00 00 03 00 … 此处0x03即防竞争字节，emulation_prevention_three_byte Annex-B头解析 1C 1，代表关键帧 CH=12D，代表CodecID=12D，为hevc 01 沿用AVC中的格式 00 00 00 沿用AVC中的格式 00 00 00 01 Start code : 分隔符 40 01 … 40 01 : VPS 00 00 00 01 Start code : 分隔符 42 01 … 42 01 : SPS 00 00 00 01 Start code : 分隔符 44 01 … 44 01 : PPS]]></content>
      <tags>
        <tag>live</tag>
        <tag>video_codec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[H264码流中的avcC和Annex-B]]></title>
    <url>%2F2018%2F01%2F21%2FavcC-annexB%2F</url>
    <content type="text"><![CDATA[近期竞答直播火热，简直百花齐放，各大直播解决方案提供商为了快速抢占份额，提出各种降低延迟，同步答题卡与直播画面的方案。 其中，同步答题卡与直播画面的方案中，比较普遍的做法是在H264码流的SEI中增加相应的自定义信息，使得播放器在解码到对应的信息的时候弹出预先几秒下发的答题卡，并开始倒计时。 在这里，涉及到播放器解码H264码流的方式，播放器使用不同的解码方式可能导致SEI解析失败，甚至画面无法正常播放。 SEI是什么呢？SEI是NALU type为6的NALU，全称为Supplemental enhancementinformation，直译为补充增强信息，一般称为增强帧。此处涉及到比较基础的编码打包方面的知识，笔者也不太清楚，后续查阅资料搞明白之后与大家分享。今天先理下H264打包码流的两种格式：avcc与annex-B。 H264编码结构要说H264的打包方式，首先要讲下H264的编码结构。 H264主要分为两层：编码层(Video Coding Layer，VCL)和网络抽象层(NetworkAbstraction Layer (NAL))；前者定义了各种编码的算法，后者将前者编码的数据按照一定的方式进行打包存储或者传输。 而NAL单元(NALU)作为可以单独可以解码的结构，整个H264的码流可以理解为由多个NALU组成的。 而NALU由头部和负荷组成。 NALU的负荷由称为原始字节序列载荷(Raw Byte Sequence Payload,RBSP)，是由一串数据比特串(String Of Data Bits,SODB)加上末尾的stop-bits（使得整个NALU长度是8的倍数）组成。 另外，关于RBSP还有一个概念叫(Encapsulation Byte Sequence Packets,RBSP，不清楚要怎么翻译)。这个EBSP是在RBSP的基础上，为了防止编码出来的比特流中有跟分隔NALU的StartCodePrefix(0x00000001)有冲突，导致分隔NALU失败。所以在连续出现两个字节为0时，强制插入一个0x03字节。在解码时，再讲0x03字节删除，还原回去。称为脱壳操作（有中文资料这么称呼，不清楚有没有这么个叫法）。 看到有大神用数学公式概括了以上几个概念的关系。此处start_code为annex-b格式中的分隔符，可能是三字节的0x000001或者四字节的0x00000001，实际来看后者较多，可以认为是下图一个小缺陷。 NALU头部一个字节表明该NALU的类型，标准定义列表如下： nal_unit_type Content of NAL unit &amp;RBSP syntax structure C NAL unit type class[Annex A] NAL unit type class[Annex G &amp; H] NAL unittype class[Annex I] 0 Unspecified non-VCL non-VCL non-VCL 1 Coded slice of a non-IDR pictureslice_layer_without_partitioning_rbsp( ) 2, 3, 4 VCL VCL VCL 2 Coded slice data partition Aslice_data_partition_a_layer_rbsp( ) 2 VCL not applicable not applicable 3 Coded slice data partition Bslice_data_partition_b_layer_rbsp( ) 3 VCL not applicable not applicable 4 Coded slice data partition Cslice_data_partition_c_layer_rbsp( ) 4 VCL not applicable not applicable 5 Coded slice of an IDR pictureslice_layer_without_partitioning_rbsp( ) 2, 3 VCL VCL VCL 6 Supplemental enhancement information(SEI)sei_rbsp( ) 5 non-VCL non-VCL non-VCL 7 Sequence parameter setseq_parameter_set_rbsp( ) 0 non-VCL non-VCL non-VCL 8 Picture parameter setpic_parameter_set_rbsp( ) 1 non-VCL non-VCL non-VCL 9 Access unit delimiteraccess_unit_delimiter_rbsp( ) 6 non-VCL non-VCL non-VCL 10 End of sequenceend_of_seq_rbsp( ) 7 non-VCL non-VCL non-VCL 11 End of streamend_of_stream_rbsp( ) 8 non-VCL non-VCL non-VCL 12 Filler datafiller_data_rbsp( ) 9 non-VCL non-VCL non-VCL 13 Sequence parameter set extensionseq_parameter_set_extension_rbsp( ) 10 non-VCL non-VCL non-VCL 14 Prefix NAL unitprefix_nal_unit_rbsp( ) 2 non-VCL suffix dependent suffix dependent 15 Subset sequence parameter setsubset_seq_parameter_set_rbsp( ) 0 non-VCL non-VCL non-VCL 16 Depth parameter setdepth_parameter_set_rbsp( ) 11 non-VCL non-VCL non-VCL 17 – 18 Reserved non-VCL non-VCL non-VCL 19 Coded slice of an auxiliary coded picture without partitioningslice_layer_without_partitioning_rbsp( ) 2, 3, 4 non-VCL non-VCL non-VCL 20 Coded slice extensionslice_layer_extension_rbsp( ) 2, 3, 4 non-VCL VCL VCL 21 Coded slice extension for depth viewcomponent or a 3D-AVC texture view component slice_layer_extension_rbsp( ) 2, 3, 4 non-VCL non-VCL VCL 22 – 23 Reserved non-VCL non-VCL VCL 24 – 31 Unspecified non-VCL non-VCL non-VCL 基础知识讲得差不多了，下面进入正题，看下什么是avcc和annex打包方式呢。 以上已经提过，H264的码流有多个NALU组成，那边NALU是如何组成AVCC的呢，每个NALU又该如何去分隔呢，此处便涉及到了AVCC和annex-B两种格式。 avcCavcC的码流打包方式是在每个NALU前面添加一个标记NALU长度的字段，该字段可能的长度为1字节或者2字节或者4字节，通常为了保证该字段可以足够描述NALU的长度，会设置为4个字节。 而该字节的长度可以通过解析extradata（也称为sequence header）的头信息来获取，也就是常说的avc头。以下为该头部信息的解析格式： aligned(8) class AVCDecoderConfigurationRecord { unsigned int(8) configurationVersion = 1; unsigned int(8) AVCProfileIndication; unsigned int(8) profile_compatibility; unsigned int(8) AVCLevelIndication; bit(6) reserved = ‘111111’b; unsigned int(2) lengthSizeMinusOne; bit(3) reserved = ‘111’b; unsigned int(5) numOfSequenceParameterSets; for (i=0; i&lt; numOfSequenceParameterSets; i++) { unsigned int(16) sequenceParameterSetLength ; bit(8*sequenceParameterSetLength) sequenceParameterSetNALUnit; } unsigned int(8) numOfPictureParameterSets; for (i=0; i&lt; numOfPictureParameterSets; i++) { unsigned int(16) pictureParameterSetLength; bit(8*pictureParameterSetLength) pictureParameterSetNALUnit; } if( profile_idc == 100 || profile_idc == 110 || profile_idc == 122 || profile_idc == 144 ) { bit(6) reserved = ‘111111’b; unsigned int(2) chroma_format; bit(5) reserved = ‘11111’b; unsigned int(3) bit_depth_luma_minus8; bit(5) reserved = ‘11111’b; unsigned int(3) bit_depth_chroma_minus8; unsigned int(8) numOfSequenceParameterSetExt; for (i=0; i&lt; numOfSequenceParameterSetExt; i++) { unsigned int(16) sequenceParameterSetExtLength; bit(8*sequenceParameterSetExtLength) sequenceParameterSetExtNALUnit; } } } 其中第五个字节的最后两位unsigned int(2) lengthSizeMinusOne;便是上述标记NALU长度的字段的长度。 在extrdata中还包含了SPS的个数，SPS的长度和SPS，以及PPS的个数，PPS的长度和PPS。对于解码器来说，上述参数都十分重要。 Annex-BAnnex-B是指H264的标准文档中的附录B中给的H264码流打包方式。相对于avcC来说，Annex-B打包方式没有固定长度的字段来表明NALU的长度，而是使用固定字符串来作为不同NALU的分隔符，有0x000001和0x00000001，也就是前文提到RBSP时提到过的START CODES。为了为了防止NALU中本身带有0x000001或者0x00000001而导致的解析分隔失败，引入了0x03的防止竞争字节。这种防止竞争操作同样适用与avcC格式。 Annex-B格式中的SPS和PPS也以NALU的方式放在码流的首部，不像avcC需要将SPS和PPS格式化在extrdata中。 后续贴几张十六进制的图 新增flv实例分析2018年1月25日AVCsequenceheader 00 00 09 onMetadata结束位 00 00 02 F8 previousTagSize 000002F8H=760D，代表前tag长度为760字节 09 TagType 09H=09D，代表video（12H=18D，script；08H=08D，audio） 00 00 2D DataSize 00002DH=45D，代表实际的TagSize长度为45个字节 00 00 00 时间戳，单位毫秒 AVC头时间戳为0 00 扩展时间戳，单位毫秒，作为基本时间戳的补位，补在基本时间戳的高位 AVC头扩展时间戳为0 00 00 00 StreamId，默认为0，作用不明 17 前四位为FrameType，此处为1，代表关键帧 1: keyframe (for AVC, a seekableframe) 2: inter frame(for AVC, a non -seekable frame) 3 : disposable inter frame(H.263only) 4 : generated keyframe(reserved forserver use only) 5 : video info / command frame 后四位为CodecID，此处为7，代表AVC编码 1: JPEG (currently unused) 2: Sorenson H.263 3 : Screen video 4 : On2 VP6 5 : On2 VP6 with alpha channel 6 : Screen video version 2 7 : AVC 由于上述的CodecID为7，所以下面为AVCVIDEOPACKET 00 AVCPacketType，此处为0，代表AVCsequenceheader 0–AVC sequence header 1–AVC NALU 2–AVC end of sequence 00 00 00 由于此处是AVCVIDEOPACKET内容，解析为CompositionTime Offset，含义不明 接下来一串到下一个tag之前的PreviousTagSize都是AVC的内容，AVCDecoderConfigurationRecord。根据14496-15标准解析。 00 00 00 38 这个tag的大小。38H=56D，代表这个tag长度为56字节。 NAL units 27 AVC的非inter frame 01 AVC NALU数据 00 00 00 由于此处是AVCVIDEOPACKET内容，解析为CompositionTime Offset，含义不明 00 00 00 09 下一个NALU的长度为9字节 06 NALU header为6，代表为NALU type为SEI 00 00 0F 61 1B 9B D9 39 NAL中的实际内容，此项为SEI的内容。 00 00 02 23 下一个NALU的长度为223H=563D字节 41 9A … 7E E0 NALU的内容 其中第一个字节为nal header，包含以下三个内容 forbidden_zero_bit nal_ref_idc nal_unit_type 此处41H=‭01 00 00 01‬B， 首位是0，符合要求，语法无错误 第二位到第三位是10，代表优先级是2 第四位到第八位为00001B=1D，表示该nal_unit_header=1，代表非IDR不可分区的slice 00 00 02 54 代表前面flv tag size是254H=596D字节。]]></content>
      <tags>
        <tag>live</tag>
        <tag>video_codec</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[FFmpeg测试序列]]></title>
    <url>%2F2018%2F01%2F01%2Fffmpeg-test-stream%2F</url>
    <content type="text"><![CDATA[经常需要做测试以及功能验证，每次都要找个视频文件或者线上拉一路流推流。在某些测试场景下，视频文件和线上的流都存在一定的码率波动，对于实际的测试数据有一定的影响。所以需要一路码率、帧率、GOP等参数可调且尽可能标准的测试流，并且使用方式要尽可能的简答，适用大多数的场景。 一般机器都安装FFmpeg，所以打算用FFmpeg实现测试流的生成。查阅资料发现FFmpeg的lavfi自带简单的测试视频，利用ffmpeg本身的一堆编码参数便可以得到想要的标准测试流。 FFmpeg安装FFmpeg的安装，参考官网的指南足矣。其他的安装指南写得再好，还是没有官方的好，而且附带中文版，集成了几乎平时用到的所有lib。 CentOS安装FFmpeg指南 我在一台VPS上安装X265库的时候出了个问题： 我通过以下操作解决： 卸载yum原本的yasm yum remove yasm 将按照官方指南中安装的高版本的yasm链接到PATH ln -s /root/bin/yasm/usr/bin/yasm 安装完毕 测试流生成视频利用lavfi生成测试视频，查到以下说明，按图索骥即可生成测试图像。 http://www.bogotobogo.com/FFMpeg/ffmpeg_video_test_patterns_src.php 此处我采用的参数如下，使用testsrc这个图像，很有小时候周二下午的回忆。 -f lavfi -i "testsrc=size=1920x1080:rate=30:duration=5" 参数含义： 参数 含义 testsrc 使用testsrc作为测试画面 size 分辨率 rate 帧率 duration 持续时间 音频测试音频采用sine正弦波。可条件频率，采样率等参数。具体参考官网说明 https://lists.ffmpeg.org/pipermail/ffmpeg-cvslog/2013-March/062382.html 此处我采用的参数是： -f lavfi -i "sine=frequency=440:sample_rate=44100:beep_factor=4:duration=5" 参数含义： 参数 含义 sine 使用正弦波信号作为输入 frequency 正弦波频率 sample_rate 音频采样率 beep_factor 每秒产生一个蜂鸣，蜂鸣频率为正弦波频率的四倍 duration 持续时间 合成测试流将以上视频和音频作为FFmpeg的输入，通过ffmpeg自带的一些编码参数和码率控制参数输出。 ffmpeg -f lavfi -i testsrc=duration=5:size=1920x1080:rate=300 \ -f lavfi -i sine=frequency=440:sample_rate=44100:beep_factor=4:duration=5 \ -acodec libfdk_aac \ -vcodec libx264 -bf 0 -b:a 100k -b:v 1900k -bufsize 1000k \ -r 30 -g 30 -sc_threshold 0 \ -profile baseline -pix_fmt yuv420p \ -f flv test.flv 输出画面如下： 观察生成的test.flv，发生其码率并不是指定的音频100kbps，视频1900kbps，而是只有730kbps。 # ffmpeg -i test.flv ... Input #0, flv, from 'test.flv': Metadata: encoder : Lavf58.3.100 Duration: 00:00:05.08, start: 0.000000, bitrate: 730 kb/s Stream #0:0: Video: h264 (Constrained Baseline), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 1900 kb/s, 30 fps, 30 tbr, 1k tbn, 60 tbc Stream #0:1: Audio: aac (LC), 44100 Hz, mono, fltp, 100 kb/s 无论如何修改指定的码率的值，输出码率总是明显小于指定值。 查阅资料后，使用x264的参数，启用CBR模式，解决问题，码率稳定在2000kbps左右： ffmpeg -f lavfi -i testsrc=duration=5:size=1920x1080:rate=30 \ -f lavfi -i sine=frequency=440:sample_rate=44100:beep_factor=4:duration=5 \ -acodec libfdk_aac -b:a 100k \ -vcodec libx264 -x264opts bitrate=1900:vbv-maxrate=1900:vbv-bufsize=1000:nal_hrd=cbr \ -r 30 -g 30 -sc_threshold 0 \ -profile baseline -pix_fmt yuv420p \ -f flv test.flv 以上FFmpeg参数含义： 参数 含义 -acodec libfdk_aac 指定音频编码为aac格式 -b:a 100k 指定音频编码输出码率为100kbps -vcodec libx264 指定视频编码为h264格式 -x264opts 启用x264参数 -x264opts bitrate=1900 x264参数：指定视频输出码率为1900kbps -x264opts vbv-maxrate=1900 x264参数：指定视频输出的最高码率为1900kbps -x264opts vbv-bufsize=1000 x264参数：指定视频编码的buffer为1000kb -x264opts nal_hrd=cbr x264参数：设置HRD为CBR，严格按照指定码率转码 -r 30 指定输出帧率为30fps -g 30 指定输出视频GOP为30帧 -sc_threshold 0 视频编码关闭 scenecut模式，用以不再自动生成I帧 -profile baseline 指定视频编码规则为baseline -pix_fmt yuv420p 指定输出数据格式为yuv420p，baseline只支持这种 -f flv 指定输出封装为flv格式 # ffmpeg -i test1.flv ... Input #0, flv, from 'test1.flv': Metadata: encoder : Lavf58.3.100 Duration: 00:00:05.05, start: 0.000000, bitrate: 1975 kb/s Stream #0:0: Video: h264 (Constrained Baseline), yuv420p(progressive), 1920x1080 [SAR 1:1 DAR 16:9], 1900 kb/s, 30 fps, 30 tbr, 1k tbn, 60 tbc Stream #0:1: Audio: aac (LC), 44100 Hz, mono, fltp, 100 kb/s At least one output file must be specified 此处观察FFmpeg打印的日志发现，两次转码只在x264的参数上差了一个指标，如下两图，下图指定了nal_hrd=cbr。 那么这个nal_hrd=cbr又是什么鬼呢？ HRD？没搞明白上述两者的唯一区别便是nal_hrd是否有设置成CBR，CBR(Constant Bitrate, 常数比特率 ) ABR(Average Bitrate)VBR(Variable Bitrate)只是x264按下不表。并没有查到相关资料，没有搞明白这些跟HRD有啥关系。 假想码流调度器(hypothetical reference decoder, HRD)，wiki上说在264标准中，HRD已经被VBV代替了，也就是设置的vbv-maxrate和vbv-bufsize两个参数。不清楚为什么还需要设置HRD为CBR模式。 关于VBV中vbv-maxrate和vbv-bufsize两个参数的关系，这个文章中有所解释：http://www.bretl.com/mpeghtml/VBV.HTM 实际使用ffmpeg -re -f lavfi -i testsrc=duration=5:size=1920x1080:rate=30 \ -re -f lavfi -i sine=frequency=440:sample_rate=44100:beep_factor=4:duration=5 \ -acodec libfdk_aac -b:a 100k \ -vcodec libx264 -x264opts bitrate=1900:vbv-maxrate=1900:vbv-bufsize=1000:nal_hrd=cbr \ -r 30 -g 30 -sc_threshold 0 \ -profile baseline -pix_fmt yuv420p \ -f flv rtmp://127.0.0.1:1935/xujk.test.com/live/stream]]></content>
      <tags>
        <tag>live</tag>
        <tag>FFmpeg</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网卡缓冲值问题-续]]></title>
    <url>%2F2017%2F12%2F23%2FNIC-buffer-issue-Cotinued%2F</url>
    <content type="text"><![CDATA[使用ip命令查看网状态。ifconfig命令已多年不再更新，从CentOS7开始，发行版的mini系统已不再自带ifconfig工具，取而代之的是ip命令。 其实质是iproute2套件取代了net-tools套件，ifconfig便是后者中一个工具。两者的简单对比，从网上找到张图： 查看网卡统计数据使用ip -s link查看link的统计数据： 以上各个统计指标的含义为： 指标 含义 errors 网线损坏或者网卡协商模式错误或者速率不匹配导致的错误。 dropped iptables或者其他规则或者内核读取网卡数据的buffer满导致的丢包。 overrun 网卡的驱动buffer满导致的overruns。 carrier 网线接触不良或者网线损坏或者交换机故障。 collsns 一般而言是0。若非零，代表双工模式的协商问题。若数值很小且不再增长，代表只是刚接入的时候故障，现已正常。 网卡buffer网卡buffer设置上篇已提到，在网卡统计中出现overruns时，需要确定是否是由于网卡buffer设置不当导致的。使用ethtool -g eth0查看当前设置，具体查看上篇。 值得说明的是，此处的数值大小并不是代表可以缓冲多大的数据，而是指可以缓冲的数据帧(frame)的数量。 网卡buffer工作原理网卡buffer会采用环形缓冲(ring buffer)的形式，其也是FIFO的一种实现方式，设计非常简单，也比较稳定，在较为底层的数据传输中使用广泛。其工作原理大致如下图所示，具体可以查看wiki。 其他注意事项有两个需要注意的地方： buffer设置使用ethtool -G eth0 rx 256设置接收buffer后，NIC会有个down/up的操作，会出现瞬时的断网，在网卡吞吐量较大时，副作用明显。 另外每次系统重启之后，该设置会失效，需要将该设置命令写入开机启动脚本/etc/rc.local中。 延迟网卡的buffer并不是越多越好，在接入带宽较低的情况下，设置很大的带宽导致数据包传输的延迟。 如在1Mbps接入带宽，MTU=1500字节的情况下，设置tx buffer=256帧。假设每个包刚好都是1500字节，则填充满buffer需要1500*256=384,000字节，也就是3,072,000比特。1Mbps每秒最多传输1024*1024=1,048,000比特的数据，当最新的一个包进入到buffer的时候，需要3s才能发送出去，会造成3s的数据延迟。 在有巨型帧(Jumbo Frame)时，每个帧长度更长，导致需要更多的时间充满buffer，延迟更久。 内核参数以上所说的buffer均指的是网卡及其驱动程序所使用的buffer，另外还有个内核使用的buffer，用以从网卡读取数据帧所用，在内核参数中设置。 BQL此处有个概念叫starvation)，中文有翻译成饿死，即网卡从ring buffer读取数据的时候，buffer中没有数据，次时设备空转一次，造成浪费，称为starvation。避免starvation是个十分复杂的问题，一个有效的办法便是增大ring buffer的长度，使得内核可以存放跟多的数据到队列中，减少starvation产生的概率。 但是增大ring buffer长度可能会导致上节中描述的发包延迟现象，因此出现了BQL。 在3.3.0内核之后，linux 内核自身会通过字节队列限制(Byte Queue Limits,BQL)自动调整数据包排队的数量，以避免在ring buffer中排队的数据包太多导致的发送延迟。实质上是在IP栈和drive queue之间加了一层，对进入drive queue的数据进行调度，避免队列满而导致延迟，同时也减少buffer长度。 这边有些相关资料，留作备份，暂时看不懂，也没需求，先不看了。 https://www.linuxplumbersconf.org/2012/wp-content/uploads/2012/08/bql_slide.pdf http://www.linuxplumbersconf.org/2011/ocw/sessions/171 /proc/sys/netIP栈允许到ring buffer排队的数据包数量可以在proc/sys/net/core/netdev_max_backlog中设置。另外在/proc/sys/net和/etc/sysctl.conf中有很多网络相关的内核参数，具体可以参考这篇博文。 参数（路径+文件） 描述 默认值 优化值 /proc/sys/net/core/rmem_default 默认的TCP数据接收窗口大小（字节）。 229376 256960 /proc/sys/net/core/rmem_max 最大的TCP数据接收窗口（字节）。 131071 513920 /proc/sys/net/core/wmem_default 默认的TCP数据发送窗口大小（字节）。 229376 256960 /proc/sys/net/core/wmem_max 最大的TCP数据发送窗口（字节）。 131071 513920 /proc/sys/net/core/netdev_max_backlog 在每个网络接口接收数据包的速率比内核处理这些包的速率快时，允许送到队列的数据包的最大数目。 1000 2000 /proc/sys/net/core/somaxconn 定义了系统中每一个端口最大的监听队列的长度，这是个全局的参数。 128 2048 /proc/sys/net/core/optmem_max 表示每个套接字所允许的最大缓冲区的大小。 20480 81920 /proc/sys/net/ipv4/tcp_mem 确定TCP栈应该如何反映内存使用，每个值的单位都是内存页（通常是4KB）。第一个值是内存使用的下限；第二个值是内存压力模式开始对缓冲区使用应用压力的上限；第三个值是内存使用的上限。在这个层次上可以将报文丢弃，从而减少对内存的使用。对于较大的BDP可以增大这些值（注意，其单位是内存页而不是字节）。 94011 125351 188022 131072 262144 524288 /proc/sys/net/ipv4/tcp_rmem 为自动调优定义socket使用的内存。第一个值是为socket接收缓冲区分配的最少字节数；第二个值是默认值（该值会被rmem_default覆盖），缓冲区在系统负载不重的情况下可以增长到这个值；第三个值是接收缓冲区空间的最大字节数（该值会被rmem_max覆盖）。 4096 87380 4011232 8760 256960 4088000 /proc/sys/net/ipv4/tcp_wmem 为自动调优定义socket使用的内存。第一个值是为socket发送缓冲区分配的最少字节数；第二个值是默认值（该值会被wmem_default覆盖），缓冲区在系统负载不重的情况下可以增长到这个值；第三个值是发送缓冲区空间的最大字节数（该值会被wmem_max覆盖）。 4096 16384 4011232 8760 256960 4088000 /proc/sys/net/ipv4/tcp_keepalive_time TCP发送keepalive探测消息的间隔时间（秒），用于确认TCP连接是否有效。 7200 1800 /proc/sys/net/ipv4/tcp_keepalive_intvl 探测消息未获得响应时，重发该消息的间隔时间（秒）。 75 30 /proc/sys/net/ipv4/tcp_keepalive_probes 在认定TCP连接失效之前，最多发送多少个keepalive探测消息。 9 3 /proc/sys/net/ipv4/tcp_sack 启用有选择的应答（1表示启用），通过有选择地应答乱序接收到的报文来提高性能，让发送者只发送丢失的报文段，（对于广域网通信来说）这个选项应该启用，但是会增加对CPU的占用。 1 1 /proc/sys/net/ipv4/tcp_fack 启用转发应答，可以进行有选择应答（SACK）从而减少拥塞情况的发生，这个选项也应该启用。 1 1 /proc/sys/net/ipv4/tcp_timestamps TCP时间戳（会在TCP包头增加12个字节），以一种比重发超时更精确的方法（参考RFC 1323）来启用对RTT 的计算，为实现更好的性能应该启用这个选项。 1 1 /proc/sys/net/ipv4/tcp_window_scaling 启用RFC 1323定义的window scaling，要支持超过64KB的TCP窗口，必须启用该值（1表示启用），TCP窗口最大至1GB，TCP连接双方都启用时才生效。 1 1 /proc/sys/net/ipv4/tcp_syncookies 表示是否打开TCP同步标签（syncookie），内核必须打开了CONFIG_SYN_COOKIES项进行编译，同步标签可以防止一个套接字在有过多试图连接到达时引起过载。 1 1 /proc/sys/net/ipv4/tcp_tw_reuse 表示是否允许将处于TIME-WAIT状态的socket（TIME-WAIT的端口）用于新的TCP连接 。 0 1 /proc/sys/net/ipv4/tcp_tw_recycle 能够更快地回收TIME-WAIT套接字。 0 1 /proc/sys/net/ipv4/tcp_fin_timeout 对于本端断开的socket连接，TCP保持在FIN-WAIT-2状态的时间（秒）。对方可能会断开连接或一直不结束连接或不可预料的进程死亡。 60 30 /proc/sys/net/ipv4/ip_local_port_range 表示TCP/UDP协议允许使用的本地端口号 32768 61000 1024 65000 /proc/sys/net/ipv4/tcp_max_syn_backlog 对于还未获得对方确认的连接请求，可保存在队列中的最大数目。如果服务器经常出现过载，可以尝试增加这个数字。 2048 2048 /proc/sys/net/ipv4/tcp_low_latency 允许TCP/IP栈适应在高吞吐量情况下低延时的情况，这个选项应该禁用。 0 /proc/sys/net/ipv4/tcp_westwood 启用发送者端的拥塞控制算法，它可以维护对吞吐量的评估，并试图对带宽的整体利用情况进行优化，对于WAN 通信来说应该启用这个选项。 0 /proc/sys/net/ipv4/tcp_bic 为快速长距离网络启用Binary Increase Congestion，这样可以更好地利用以GB速度进行操作的链接，对于WAN通信应该启用这个选项。 1 1 参考资料QUEUEING IN THE LINUX NETWORK STACK 这边文章包罗了很多内容，非常值得细度。]]></content>
      <tags>
        <tag>LINUX</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[网卡缓冲值问题]]></title>
    <url>%2F2017%2F12%2F17%2FNIC-buffer-issue%2F</url>
    <content type="text"><![CDATA[近期遇到一台推流的机器，反馈推流卡顿，查看确实整体丢帧率较高。但机器性能正常，未见明显跑高现象。ifconfig发现网卡dropped和overruns高，并且有持续增高的现象。 确认交换机以及网线无异常后，最终发现网卡缓存值设置过小，导致在大量接收数据的情况下，出现overruns的现象。 网络逻辑模型半路出家，对于网络的东西一直一知半解，顺便学习下网络模型吧。 网络的逻辑模型，最近在豆瓣读书看到一个很好的介绍，点击阅读，想不到豆瓣也有技术文章。 物理层各种物理信号，如电压、亮度，振幅等表示0101010的二进制信息。 链接层也称为数据链路层，通过物理寻址，将比特流转化为逻辑数据，使用到mac地址。将比特流包装为帧，帧中包含有来源地址(Source, SRC)和目的地址(Destination, DST)，能够探测错误的校验序列(Frame Check Sequence)、数据区 (payload)与数据相配套的数据类型(Type)信息。 网络层通过网关(gateway)（通常由路由器或者三层交换机实现），改写帧的格式，将一个子网的数据帧转发到另一个子网，实现不同子网之间的通信，使用到IP地址。 传输层进程间通信，如TCP和UDP使用端口号区分不同进程。 应用层HTTP，FTP等，更为高级的有各个程序自定义的逻辑。 网卡收包功能网卡是物理层和数据链路层设备。由于发数据基本不会出现丢包的现象，此处支持收数据的问题。 网卡接收到帧数据后，首先根据头部的序言(preamble)（用于调整时钟）、帧的起始信号(SFD, start frame delimiter)、目的地(DST, destination)和发出地(SRC, source)、类型(Type)和尾部的校验序列(CRC)（用于校验数据是否完整）这些信息进行校验，随后通过硬中断将帧copy到内存，交由内核处理。 网卡缓冲值此处涉及到的缓冲有两个，一个为网卡的硬件缓冲，另一个是内核的缓冲。网卡驱动会采用硬中断的方式将接收到的数据从硬件缓冲copy到内核缓冲。 使用ethtool工具可以查看设置当前网卡缓冲值的大小。ethtool -g eth0 图中上面的数值表示网卡支持的最大缓冲值，下面的表示目前设置的值。可以使用ethtool -G eth0 rx 128 网上资料反馈设置缓冲值会导致网络down/up，瞬时网络中断。实际设置时，概率性出现网络中断。原因不明。 另外注意的是，改设置只是临时生效，每次系统重启时，会重新设置，最好的办法是将命令加入开机执行rc.local。 另另外：网卡缓冲值分为普通fifo buffer和ring buffer 环形缓冲，等学习之后再补充。]]></content>
      <tags>
        <tag>LINUX</tag>
        <tag>network</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十一月的一些小想法（三）]]></title>
    <url>%2F2017%2F11%2F25%2Fmeander-in-November-3%2F</url>
    <content type="text"><![CDATA[书接上回。 想这么多有的没的，实在是丢人现眼，讲点正事吧。 关于笔记上半年以来，公司开始对于员工权限做各种限制与规范，对于网盘和USB也有限制。对于工作效率和公司内部资料安保的取舍不做评价。要吐槽的是，公司也禁止了各种云笔记，确实不方便的很。互联网诞生于自由分享，确乎现今的主题早已不是自由分享了。 关于笔记软件，其实接触得还是蛮早的，在12年就开始使用有道云笔记记录些奇奇怪怪的东西了。不过学生时代真的要记的东西少得可怜，多的倒是些无病呻吟的絮叨。现在已经不忍心打开看了，太羞耻😅。 13年的时候，参加一场关于设计的讲座分享，一位姑娘的案例是印象笔记。Evernote中文翻译成印象笔记，不仅跟logo契合，而且有个说法是大象永远不会忘记，翻译成印象笔记十分巧妙，浑然天成。这点我倒是也永远不会忘记了。于是乎，也用了段时间的印象笔记。随着印象笔记慢慢更新迭代，其功能越来越复杂，也越来越吃资源，用得越来越少。 15年，大三好多课没选上，没事干，居然萌生了写本小说的妄想😂。咸鱼淘了台Microsoft的surface，有空就去图书馆码字。小说肯定流产了。不过surface确实惊艳到我了，被别人问起设备是什么的时候也是逼格满满。也让我第一次接触了到OneNote。 不得不说，office的生态太无敌，OneNote出生就是含着金汤匙的。作为Android和IOS的顶级开发者和自家UWP平台的一般般开发者，OneNote本身多平台的应用质量还是非常不错的。linux就不管了，才不装逼的用linux系统办公呢。除了不支持markdown以及复制默认粘贴图片外，对于我来说基本已经满足了。markdown没有也问题不大，基本排版OneNote也是很方便的。重要的是免费和后面有微软爸爸，放心。 之后到工作至今，一直使用的是OneNote，随着笔记条数越来越多，惯性也随之变大，已经不能像以前一样随便从云笔记A迁到云笔记B了。因此笔记及时整理和笔记的分门别类变得尤为重要。 工作以后OneNote里塞了一堆东西，基本都放在几个tab里，数量多了之后严重影响了后续查阅，终于还是花了一个周六，把OneNote整理了下，删除了大量乱七八糟已经没有用的记录，将一些记录进行归档，使得整个笔记本更有层次。具体怎么整理是每个人自己的想法问题了，从没有定论。贴张图😜 工具技能工作当中，经常需要从大量的日志中分析某些指标，排查问题。常规的工具，Excel和shell已经足够。linux内置的awk、sed等工具已经足够强大到可以满族几乎所有的日常日志数据处理需要。 所以也一直没有考虑是否要学习另外的工具。 近期遇到个场景是，需要将多个终端的数据实时同步一台中心机器上。而公司的机器都有安全限制，无法自行安装软件，且终端数量较多，不方便操作。考虑过将数据落地到磁盘，定时起个rsync将数据同步到中心机器上。由于安全限制，终端之间无法直接进行rsync操作（获取不到用户权限）。 恰好最近在考虑是不是学习下python，觉得python确实在某些方面有独到的优势。而且python这么多modules，实现某些功能比shell简单太多了。 经同事推荐，大概看了下廖雪峰的python教程，在中心机器上用python起了个简单的HTTPServer，接收终端机器post过来的数据，并做了简单处理。在终端机数量一定的情况，可以满足要求了。 一些感悟： 身为产品工程师（公司的职位这么写的😂），有些工具还是最好掌握下的，对于实际工作帮助很大。 python确实是强大的很，但是通用性并不是很好，在类似公司这里限制很强的机器上并不一定都能跑起来。而shell虽然有些功能难以实现，但是通用性非常强，基本脚本实在另一台机器上跑。 工具只是工具而已，并不需要执着某个工具，抱有一个工具吃遍天下的想法。也不用什么工具都想要知道，搞得学了一堆杂七杂八的东西。实际还是需求驱动是最好，能够快速解决问题的工具就是最好的。 其他传输协议直播发展至今，功能上来说，各家解决方案提供商也趋于一致。已经到了开始比拼质量的阶段了。比如传输层协议，tcp/ip协议簇。 tcp内核传输一些策略可能会影响到客户端接收数据，在直播这样较为敏感的场景下，导致了卡顿。因为tcp内核的一些参数也需要进行特定的调整。google的tcp/ip拥塞控制算法是比较流行的一套方案，可以实时基于发送速率和RTT调整tcp窗口和速率，实现对拥塞的快速响应。 由于并不是科班出身，对这些东西基本就知道几个概念，既然用得着，得找时间好好了解下网络传输的协议。这篇《协议森林》可以好好看看，很适合我这样没有基础的。 另外http和rtmp这类更高级的协议也应该多多了解些。可以更好地理解整个数据传输过程。 工作成果展示每周五都要写周报。有个问题是，经常发现比较重要的事情，领导似乎都不太关心，而随便提了一句的事情，领导可能会私聊来了解情况。看来每个人的关注点都不太一样，写周报这类工作进展的东西，并不能按照自己的实际工作时间来侧重。具体写啥，是门艺术，得好好琢磨。 发散思维近期有个客户一直投诉质量差，需要进行调优。常规的调整策略都使用了，没啥用。 感觉已经黔驴技穷了，所以这个时候，需要各种头脑风暴和奇思妙想了。很多事情并不是都有套路的，说不定答案就在拉💩的灵光一闪。 WebRTC最近这个词经常看到，这套方案似乎特别适合做直播连麦，找时间可以了解下。（又是google的，这么强）]]></content>
      <tags>
        <tag>痴人说梦</tag>
        <tag>工作</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十一月的一些小想法（二）]]></title>
    <url>%2F2017%2F11%2F19%2Fmeander-in-November-2%2F</url>
    <content type="text"><![CDATA[书接上回。 今天讲下最近关于电影和音乐的一些想法。 电影看电影比看书是勤快多了。人呐，总是爱挑简单的事做，懒胚。 院线档期的大片和其他一些网上的盗版电影倒是都看了不少，大概以下几部让人印象很是深刻： 降临 《降临》是今年年初在大陆上映的一部科幻片。上映时，霸屏朋友圈蛮久的，被很多人称为硬科幻。当时没有去电影院支持，现在只能下载盗版BT了。 故事还是比较简单的，地球突然出现一批外星文明的飞船，身为人类语言学家的女主和身为物理学（还是数学）家的男主一起进入飞船试图与外星人交流。最终女主在和外星人的接触过程中逐渐学会了外星文字。而外星文字跳出时间的限制知晓未来与过去。女主因此预见到了未来：和男主结合，育有一女，女儿后来得不治之症死亡，男主无法接受离去。 其实这片并不算纯粹的科幻片，应该算是科幻片与文艺片的结合，影片更多的探讨了一些哲学的概念，关于时间，人类发展，未来。 片子中外星人使用的文字倒是很神奇，跟中国的水墨画十分相似，其中的意思包含在不同的晕染之中（是不是想说我们中国才能拯救世界，啊哈哈哈）。 豆瓣有一篇脑洞很大的影评，你不知道的《降临》背后的恐怖真相，闲暇时可以读读。作者意淫了一把大的，认为外星文字就是中文的演变，确实是牛逼的中文呀。 片尾有个有趣的情节是，女主通过外星文字知道了自己的未来：她会和男主会在一起，所生的女儿会因为怪病而死去，男主因此而离去。但是最后，得知了一切未来的女主还是深情的望着男主，与他拥抱在一起。这种明知前途荆棘丛生，依然无畏前行的勇气估计也是人类可以生存至今的原因吧。 超体《超体》讲述了女主意外吸收了超大量的人类胚胎时期的原始物质CH后，大脑使用率逐渐达到100%的故事。随着人脑利用率的提升，女主开始可以控制自己的身体，控制身边的物质，最后和时间空间融为一体。 本来只是像看下Scarlett Johansson的脸（顺便吐槽Scarlett的身材确实不咋地呀，不晓得为什么你们都这么爱她），想不到这电影倒是和同样是Scarlett“主演”的《她》一样惊艳到我了。片中对于人类起源，发展与未来的思考，这一套很是我的菜。 我本身还是蛮拜服中国古代那一套哲学理论的。古人认为的天地之间的规律与秩序是“道”，《老子》中所述的“道生一，一生二，二生三，三生万物”，所讲述的是人是道的转换而成的一种产物，而人又要追求道，希冀得“道”。 超体电影中，女主角意外得以快速进化，以至于可以控制身边的物质，最后超脱时间和空间，化入其中。而影片中一直出现的画面是人类的起源，生命的起源，从一片无机物质中孕育出细胞和生命。两边一对比，似乎我们追求的极致便是虚无，而我们又是从虚无中而来。这与中国古代的世界观体系，万物孕于道，而人又求道有点类似。 导演吕克·贝松或许只是像表述他所理解的未来，他所理解的人们所追求的终极目标的样子。而每个观众所体会到的或许又是另外的样子。 浪潮 《浪潮》，据说是根据实际事件改编，讲述了一位德国教师，在教授独裁政治课程时，为了让学生们对独裁统治有更形象的认识，在课堂上模拟了独裁统治的一些方式，包括发言要起立，上下课有仪式，称呼老师特定称谓等。后来愈发不可收拾，有了统一服饰，统一口号，统一的logo，最终大部分学生有了统一的思想形态，统一的行动，酿成大祸。 影片本身要说的应该是独裁统治很容易重演，希望保持警惕这样吧。但是身为一个在中国成长的人来说，这不就是我们的小学，初中，高中，甚至大学嘛。我们不是一直被要求穿校服，上课遵守纪律，喊统一口号嘛。记得小时候老师经常说的也是不要搞特殊，每个人不管在家如何，在学校大家都要一样，这样想想，好可怕，可怕，可怕。 音乐今日打算弃坑网易云音乐了，看着歌单里一批一批变灰，实在是难受得很。可惜还有十个月的会员呢。 所以说这种网络音乐提供商跟音乐版权公司签什么独家版权实在是不友好得很，不仅不利于行业内竞争，也让消费者少了很多选择项嘛。搞个会员机制，或者其他收费方式都是很不错的嘛。唉~ 吐槽完了，谈下最近几首歌。 现象七十二变罗大佑的这首歌实在是太妙。歌词开头就让我眼前一亮。 黄花岗有七十二个烈士 孔老夫子有七十二个弟子 孙悟空的魔法七十二变 我们又等到民国七十二年 …… 虽然粗看不就是四个七十二嘛，但是细想，时空交错，虚实不定，开头就特殊得很。 歌词讽刺了很多现今的虚假现象，人们道貌岸然，私下里却各种小心思。罗大佑被一些人称为中国的Bob Dylan，也不是没有原因。 高晓松在《晓说》里经常说中国人写词的水平天下无敌，谱曲的水平确实实在一般般。本人实在是没啥音乐天赋，听了几首流行音乐，对于曲谱得怎么样，实在赏析不来，不过歌词赏析的能力，想来中国人应该都是可以谈下的。 罗大佑的很多音乐的歌词在他那个鸭般的奇怪嗓音唱出来确实让人眼前一亮。《将进酒》，《鹿港小镇》，《之乎者也》都是写可以单曲循环几十遍的佳作。也不在此装逼的分析，这种东西自己爱听就好。 胡德夫学生的时候，在广播里听到胡德夫的《匆匆》，这位大爷的独特唱腔让人神清气爽，似乎放下了一切，坐在海边吹风般舒畅。这个广播节目现在还记得呢，浙江之声的《方雨大搜索》，虽然独在异乡，有时候也听下故乡的电台。 胡德夫最近应该很多人都知道了吧，看到豆瓣有他的节目，上了首页。他的音乐基本就他的自弹钢琴，一口嗓子，无它。唱腔很独特，不知道怎么形容，经常会混入台湾原住民的一些独特的方言的发音，一些简单的”啊“， ”哈“， ”哦“之类的。我这个农村进城务工人员，常年待在城市里，只听到普通话的，他的音乐确实很适合在浮躁时，放空一切，安静发呆。 胡德夫有很多经典的音乐，《匆匆》，《太平洋的风》，《牛背上的小孩》，我最喜欢的是他翻唱的Leonard Cohen的《hallelujah》，我不知道这是不是算是一首上帝颂歌，不过我听来确实净化心灵之歌。相对Cohen，胡德夫更为纯粹，如果是在赞颂上帝来看，也更为纯洁些吧。 点击下面可以尝试下~拜谢。 var ap = new APlayer({ element: document.getElementById("aplayer0"), narrow: false, autoplay: false, showlrc: 0, music: { title: "hallelujah", author: "胡德夫", url: "https://nuaaeducn-my.sharepoint.com/:u:/g/personal/toneytonight_nuaa_edu_cn/EXPRJSNKBM9KtbN9ESmsWvkBDGWocD8aYc-xxjiwEUupug?e=Kb6BvR", pic: "/music/胡德夫-Hallelujah.jpg", } }); window.aplayers || (window.aplayers = []); window.aplayers.push(ap); 体育其实并不是谈体育，我这羸弱的身体，从小就没对哪项体育活动感兴趣过。只是讲了读书，电影，音乐之类的东西之后，打算讲下身体的，不过感觉标题为体育比较和谐。标题党！标题党！！标题党！！！实在是可恶。 好了，讲下身体吧。 唉，我这羸弱的身体，体力不行就算了，工作一年，游泳圈出来了也就算了，居然有了脂肪肝，还是轻-中度脂肪肝。简直恶搞，简直恶搞，简直恶搞。 体检B超的那个姑娘，你知道你淡淡的那句“有点脂肪肝”对我有多大伤害嘛。(╯︵╰) 手机上装了个keep，装了个囚徒健身，装了个薄荷，你说说，有啥用，有啥用，有啥用。 哎，不写了，去做个十个仰卧起坐吧。 最后福利时间，传授个小技巧，与诸君共勉：]]></content>
      <tags>
        <tag>痴人说梦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[十一月的一些小想法（一）]]></title>
    <url>%2F2017%2F11%2F18%2Fmeander-in-November-1%2F</url>
    <content type="text"><![CDATA[17年的光棍节过了，有种还停留在世纪大光棍节的那天的错觉。 工作一年多，对于“脱光”早已不在期待，神奇的是对于抢购也不再热情，看来促销力度还不够呀。 这样，把脑袋里的小想法记录下来，语言组织能力薄弱得很，权当练习下打字水平吧。 光棍节所有的节日不外乎两类：纪念很有地位或者知名度的人物或者事件，纪念地位太低或者遭遇凄惨的人物或者事件。 光棍节显然属于后者。从字面本身看就对我们汪类有着深深的恶意。 购物虽然没买什么，但其实还是想买的。想买个kindle装逼。想买个最贵的kindle装逼。想买个美版的带3G上网功能的最贵的kindle oasis装逼。 没钱！！！买不起，太贵了。 光棍再闲谈下光棍吧，有个段子： 从前喜欢一个人，现在喜欢一个人。 中文还是博大精深呀。这段子怎么看都是光棍修炼着修炼着，提升了一个境界。再修炼下去是不是要变成魔法师了。不瞒你说，本人目前已经是到了”现在喜欢一个人“的境界了，也算是有点小资格来谈下这个事情了。 从前喜欢一个人从前哪只喜欢一个人呀，男人都是很花心的，尤其是年轻的男孩，见几个爱几个。 哎，回忆突然塞满了脑子，但是啥也写不出来。不写了。 现在喜欢一个人现在确实喜欢一个人。 每周一听同事炫耀周末跟妹纸去逛街的“乐趣”，私下庆幸自己没有妹纸。只怨自己天生是平足，逛街于我实在顶残忍的酷刑。 再者，我们读书人，向来是以追求自由独立为目标的，经济自由独立，活动自由独立，思想自由独立。倘使交了朋友，总要有所妥协，经济要受其管制，假期活动被其安排，脑子要求只有她，何来自由独立之思想，甚至可怕，可怕，可怕。 那一直是一个人，都自由独立了嘛？没有！这才是悲剧所在。 其实内心还是渴望爱情，但是已没有年少时只要姑娘点头，其他全部抛掉的勇气了。现在喜欢一个人的原因也只是不爱那位同事所“炫耀”的那种生活（我们汪类看来那就是炫耀）。 所以一直对外宣称自己是姐姐控，只是因为感觉上的姐姐都是那么得独立自主，即使两个人，也不用一直腻歪在一起，依然可以有可以自己的空间与时间。 但是都不腻歪在一起了，还怎么谈朋友，简直是太可恶，可恶，可恶。 这样的矛盾，估计是注定孤独一生了。 书读得越多越蠢记得看过一张图，找了下没找到，大概描绘下：图片一边是一摞书，堆很高。另一边对应三层大气，自下而上是近地面：风景秀丽，对流层：电闪雷鸣，平流层：拨云见日。大概的意思是，如果稍微读点书，会经历那一层电闪雷鸣，有足够的积累的人才可以冲破乌云，看到云上的壮阔景象。 问题是，局中人永远看步到自己所处位置的，所以无法知晓自己还离穹顶有多少步。悲哀呀悲哀。 好了，终于为自己的越来越愚蠢找了个高大上的借口。 工作后看书也不太看了，基本也就是电影电视剧看太多感到羞愧的时候，捧起本粗浅的小说来看几眼，再拿起一旁手机看几十眼。断断续续也算看了几个小故事吧。 阿城阿城之前也没听过，记得大四那年看了梁文道的一档节目，其中有一期推荐阿城的《阿城精选集》，就一直放在想读的清单里。16年下半年的某一天吧，某东搞图书类的促销活动，凑了几本，其中便有这本。 阿城本身也是个很惜字的人，这书也不厚，大概十几万字吧，换成狗血的网文，估计也就两个小时看完了吧。也怪我不是有恒心一口气看完，居然断断续续看了一年，也是罪过。亏得里面都是些一两页的小短文。 阿城的文字实在是有特点得很，描写含而不发，十分隐忍，加上其自身中西贯通，又上山下乡过，可谓见识远博。文章的情节设置看似朴实无华，却又五味无穷，这等出神入化的功力实在是叹为观止。其中《棋王》，《树王》，《孩子王》最为著名，虽然每篇都很短，顶多算个中篇，但总是可以凭几句看似随意的一个细节或者一个动作的描写，把人物和情节描写的入木三分。 阿城的文字初读感觉只是描述了情节，细想却似描绘了但是社会下人们的生活状态，再想下就要联系到浩荡的历史长河了。实在是像有魔法一般。 白先勇白先勇之前也不太了解，可能有时会看到他和红楼梦经常联系在一起吧。已经记不清是什么时候听的《锵锵三人行》中，有谈到了白先勇《台北人》中的一些情节，讲述随国民党去台湾的一些老兵的故事，觉得有些意思，就放在了想读的清单里。 16年春节过完后，回厦门的动车上，看完了《台北人》。 白先勇先生的父亲是著名的国民党著名将领白崇禧，曾任“中华民国国防部部长”，后随国民党退居台湾。白先勇经历了和曹雪芹类似的家族从巅峰慢慢衰落的过程，可能也因此白先勇十分推崇红楼梦。 《台北人》主要讲述了从大陆随国民党迁居到台湾的各层阶级，各类职业的故事。通篇还是非常悲情的，各种思乡离愁，生活艰辛，各种往昔美好生活和当前残败生活的对比，白先勇本身特殊的身份让他可以观察到各种人群的生活状态，并述诸于文字。 白先勇描写不仅有画面感，而且还有声音。开篇几篇均是迁居台湾最后客死他乡的上海人的故事，其对话用上海话演绎也没有问题。可以说是传神的很。通篇基本没有直接抒情，均是描写性和记录性的文字，但是那种失落感和追忆往昔的感情缺失扑面而来。这点可以说跟阿城有点像。 我是没有看过《红楼梦》，一直看了几章就放弃了，但是白先勇的写法跟《红楼梦》还有些类似的，其中对于人物，衣着，家具的描写和《红楼梦》的“头上戴着束发嵌宝紫金冠…”很是类似的。（既然如此，为什么《台北人》可以看完，《红楼梦》怎么看不下。） 其他Samsung版的kindle送了一本《平原上的摩西》，作者是双雪涛。这个名字实在是没听过，百度了下，算是新锐作家。不过这篇《平原上的摩西》实在是精彩得很。文字上有些先锋文学的感觉，还带些阿城的感觉，情节虽说不是特别的巧妙，但是叙述的方法很是高明。非常推荐。 《到灯塔去》，作者是弗吉尼亚·伍尔夫，以前应该学过她的《墙上的斑点》。意识流小说流派的代表作之一。没看完，还在看。第一次看意识流的小说（之前就看几页的《追忆逝水年华》和《繁华与骚动》不算），跟我想的还不一样。本来以为意识流就是作者想什么就写什么，实际上是在情节里，故事中的人物想什么，就写什么。本身意识流小说还是个小说，只是心理活动的描写更多些而已。现在才认识到这个点，惭愧。 《三体》，在大刘获雨果奖之前，就已经尝试了不下三次去看这套书了，每次都看到叶文洁到秘密军事基地就看下不去了。大刘的其他的短篇小说倒是都被我看完了。确实十分得精彩。应该找时间再一次尝试《三体》了。 最近在看郁达夫的一些中短篇的小说，主要按照这本集子看。郁达夫的小说怎么这么颓丧，跟以前课本的《故都的秋》感觉完全不一样。倒是让我联想到之前关于闽南语歌曲的一个段子： 闽南语歌曲三大主题：老娘要男人、我命怎么那么苦、老子一定会成功。 郁达夫的小说的主题倒是跟闽南语歌曲前两个主题很相似：我要女人，我好苦。关键没有最后那个我一定会成功。啊哈哈~ 看了几篇，意思都是：好想跟那个女人发生关系，但是我不能祸害她，这都是这个社会的错，我要复仇。有趣，有趣，有趣。 另外还有些描写战争年代下的人们生活的小说，由于郁达夫也是浙江人，有些描写看了也是特别的亲切。郁达夫的文字还是很有水平的，如果情绪不是很消极的情况下，看下还是可以的，如果自身很颓丧，再看郁达夫的小说，估计要忧郁症了。 英语问题英语是基本荒废了，尝试抢救了几次，感觉像是抢救不过来了。 语言说到底只是个工具，工具不用的话，肯定会生疏的。现在的状态，听说基本就是废了。写的话，基本靠词典，基本只会简单单词和句子了。终于读还能读些。可悲，可悲，怎么有种以前英语很好的错觉。 英语还是很重要滴，手机上下了个APP，就坚持一个礼拜，应该要重拾起来呀。废物，废物，废物。]]></content>
      <tags>
        <tag>痴人说梦</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ELK初体验]]></title>
    <url>%2F2017%2F09%2F24%2Fmeet-ELK%2F</url>
    <content type="text"><![CDATA[​ 近期遇到有分日志数据需要分析，计算部分不算复杂，直接shell脚本跑一遍大致也可以完成，但是其数据维度较多，分析结果不易展示。希望可以导入数据库，按照需要sql提取数据，进行展示。 ​ 对于笔者这种没有开发经验的小白来说，做这么系统是天方夜谭了。（认清现实呀） ​ 所以必须得有现成的解决方案的，附上条件： 开源的，可不希望为了这个付出大代价； 比较流行的，对于小白来说，肯定会遇到各种问题，所以最好有各种教程，有论坛； ​百度、google都可以，很容易就可以找到今天的主角，ELK，也就是elasticsearch+logstash+kibana。 ELK是什么？​ 小白对于ELK的理解比较简单，大概是这样： ​ ELK是三个独立组件组成一套数据接收，处理（简单处理），存储，以及展示的系统。 ​ 其中的优点是： 完成部署后，是实时处理数据的，十分便捷； 听说elasticsearch可以分布式部署，运作，可用性和承载量很高；（小白啥也不知道，你说好用就好用吧） 部署简单，基本就解压就可以用了； 其架构大概如此： 安装ELK系统环境​ 本次使用的为单台的CentOS 5.8的物理机。 Distributor ID: CentOS Description: CentOS release 5.8 (Final) Release: 5.8 Codename: Final java环境​ 另外这套系统全部由运行在java上，所以需要java1.8的环境，具体安装不再赘述，参考这篇博文。 # java -version java version "1.8.0_144" Java(TM) SE Runtime Environment (build 1.8.0_144-b01) Java HotSpot(TM) 64-Bit Server VM (build 25.144-b01, mixed mode) 安装ELK​ 安装上文已经介绍了，非常简单，在ELASTIC官网下载，下载解压即可。 ​ 本次使用的版本是： elasticsearch-5.5.2 logstash-5.5.2 kibana-5.5.2 配置启动logstash​ logstash进行简单的配置之后，就可以直接运行了。 简单测试​ 按照惯例会使用最简单的std输入和std输出测试logstash能否正常工作。 ./logstash-5.5.2/bin/logstash -e 'input{stdin{}}output{stdout{codec=>rubydebug}}' ​ 在标准输入中输入内容。比如test，会在标准输出打印先相关内容。 { "@timestamp" => 2017-09-19T15:24:24.021Z, "@version" => "1", "host" => "localhost", "message" => "test" } ​ 其中@timestamp字段是事件发生的时间，默认会添加。 简单配置​ 编辑该配置文件./logstash-5.5.2/config/logstash.conf，填入logstash的输入input{}，处理filter{}，输出output{}信息： input{ #输入相关配置 } filter{ #数据处理相关配置 } output{ #输出相关配置 } input{}​ input{}即输入相关配置，logstash支持文件形式(file)，标准输入(stdin)，syslog协议(syslog)，tcp(tcp)四种方式。 ​ input还支持常见的数据格式，如json，需要使用codec插件，详细不赘述。可以查看官网学习。 filter{}​ filter{}即logstash中的数据处理部分，主要有各类丰富的插件完成。这边介绍下使用的常见的几个： grok​ grok可以编码各种正则来提取所需要的信息，并且可以指定数据的格式。其基本语法为： filter { grok { match => { "message" => "Duration: %{NUMBER:duration}" } } } ​ 其中NUMBER是事先编写好的pattern，或者是自带的pattern，上例的含义为，将Duration:后符合NUMBERpattern的数据赋值给duration。 ​ grok详细操作与介绍可以参考grok官方介绍。 date​ date插件可以将日期和时间格式的数据转化成想要的格式，其中也内置很多标准的格式，其基本语法为： filter { date { match => [ "logdate", "MMM dd yyyy HH:mm:ss" ] } } ​ 上例的含义为，将logdate的日志格式转为MMM dd yyyy HH:mm:ss的形式。 ​ date详细操作与介绍可以参考date官方介绍。 json​ json插件可以对grokmatch到的变量进行json解格式，其基本用法为： filter { json { source => "message" } } ​ 上例的含义为，将source解json。 ​ json详细操作与介绍可以参考json官方介绍。 split​ split可以将某一事件按照某个字符进行拆分，比如： filter { split { field => "message" terminator => "#" } } ​ 上例的含义为，将messagefield按照#进行拆分。 ​ split详细操作与介绍可以参考split官方介绍。 其他​ 关于filter其他插件以及使用方法，可以查看这里。 output{}​ logstash支持非常多的输出选项，输出到文件，输出到stdout，输出到端口，输出到email等，比如常见的输出到elasticsearch： output { elasticsearch { hosts => ["192.168.0.2:9200"] index => "logstash-%{type}-%{+YYYY.MM.dd}" document_type => "%{type}" flush_size => 20000 idle_flush_time => 10 sniffing => true template_overwrite => true } } ​ elasticsearch输出参数非常多，可定制性也很强，可以从elasticsearch官方介绍 了解详细的信息。 ​ 其他形式的输出也可以从output官方介绍了解。 其他​ 关于logstash的其他配置和功能，可以查看其官方教程。 启动logstash./logstash-5.5.2/bin/logstash -f ./logstash-5.5.2/conf/logstash.conf Elasticsearch​ elasticsearch经过简单配置，直接运行即可。 vi ./config/elasticsearch.yml ... #修改cluster名称 cluster.name: test_cluster #修改node名称 node.name: node-1 #填写IP network.host: ***.***.***.*** #填写端口 http.port: 9200 ​ 其他配置根据需要配置。总体来说配置的内容较少。直接启动程序，测试9200是否可以正常运行。 ./bin/elasticsearch curl http://***.***.***.***:9200/ { "name" : "node-1", "cluster_name" : "test_cluster", "cluster_uuid" : "lIW3ERtnQGqoXd_fPZgr6Q", "version" : { "number" : "5.5.2", "build_hash" : "b2f0c09", "build_date" : "2017-08-14T12:33:14.154Z", "build_snapshot" : false, "lucene_version" : "6.6.0" }, "tagline" : "You Know, for Search" } ​ 返回es的一些信息，表示es正常运行。 注意事项: ​ ES本身不允许root运行，并且对于运行有些条件。如果机器性能达不到要求，可以在./configjvm.options中调低java运行参数。 ​ 另外，如果有以下报错，请更改响应的参数。 ERROR: [3] bootstrap checks failed [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at least [65536] [2]: max number of threads [1024] for user [elk] is too low, increase to at least [2048] [3]: max virtual memory areas vm.max_map_count [65530] is too low, increase to at least [262144] sysctl -w vm.max_map_count=262144 vim /etc/security/limits.conf elk soft nofile 65536 elk hard nofile 65536 elk soft nproc 2048 elk hard nproc 4096 ​ 出现以下报错 system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk ​ 因为Centos6不支持SecComp，导致启动失败，详情可以看github这个issue。 ​ 解决办法是关闭下面两个选项： vi ./config/elasticsearch.yml bootstrap.memory_lock: false bootstrap.system_call_filter: false kibana​ kibana经过简单配置，直接运行即可。 vi ./config/kibana.yml ... #配置端口 server.port: 5601 #配置host server.host: "***.***.***.***" #配置es查询地址 elasticsearch.url: "http://124.164.8.39:9200" ​ 其余配置项可以保留默认值。 ./bin/kibana #curl探测成功即可。 curl -I http://124.164.8.39:5601 HTTP/1.1 200 OK kbn-name: kibana kbn-version: 5.5.2 cache-control: no-cache Date: Sun, 24 Sep 2017 08:05:21 GMT Connection: keep-alive 结语kibana界面： kibana绘图： 其他功能研究中~ st=>start: origin e=>end: browser op1=>operation: logstash处理数据后发送ES op2=>operation: ElasticSearch op3=>operation: kibana从ES读取数据展示 st->op1->op2->op3->e{"theme":"simple","scale":1,"line-width":2,"line-length":50,"text-margin":10,"font-size":12} var code = document.getElementById("flowchart-0-code").value; var options = JSON.parse(decodeURIComponent(document.getElementById("flowchart-0-options").value)); var diagram = flowchart.parse(code); diagram.drawSVG("flowchart-0", options);]]></content>
      <tags>
        <tag>LINUX</tag>
        <tag>analysis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[hexo安装与设置]]></title>
    <url>%2F2017%2F08%2F26%2Fhexo-setup-and-config%2F</url>
    <content type="text"><![CDATA[此篇简单介绍hexo和主题的安装，以及一个配置项。 安装hexo安装Git和node.js后，打开gitbash npm install -g hexo-cli 一些必要的插件将会自动依赖安装，不需要另行安装。 初始化hexo hexo init "C:\Users\jingkaixu\OneDrive\GitHub" 会有几个warning，不影响最终的安装结果。此时hexo已完成安装。初步可以使用。 安装主题下载喜欢的主题，并配置启用。配置参考主题提供方所给文档。此处采用比较流行的NexT主题。 主题配置文件注意每个配置项的：之后要有个空格，否则会报错。 NexT安装可以参考其官方文档，不再赘述。NexT 上传方式配置deploy方法，由于使用了github的page服务，所以选择ssh deploy。 在本地生成ssh指纹后，添加到github的deploy keys中。 具体可以参考这条百度经验。 设置apple-touch-iconSafari浏览器收藏的时候，不会采用favicon.ico最为默认图标，而是有个apple-touch-icon作为图标，可以参考苹果官方文档，此时需要在主题目录中修改\themes\next\layout\_custom\header.swig文件，在其中新增一个&lt;linkrel=&quot;apple-touch-icon&quot; href=&quot;apple-touch-icon.png&quot;/&gt;，如此再生成静态文件时，会自动加入这一行代码。再在source目录中加入信号的apple-touch-icon.png即可。]]></content>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[grep awk匹配字符串性能对比]]></title>
    <url>%2F2017%2F08%2F20%2Fgrep-awk-matching-performance%2F</url>
    <content type="text"><![CDATA[近期遇到个场景，需要在某个较大的文本中匹配特定的一批字符串，并将其滤除或者打印出来。 使用了shell的grep和awk，对于这两个工具的文本处理效率和方法有了些基本的认识。 grep最初的想法是grep命令，即： grep -Ff A B #打印文件A和文件B中有相同字符串的行 grep -vFf A B #打印文件B中有，但是文件A中没有的行 由于待处理的文件有百万甚至千万行，直接grep导致将内存爆炸。测试使用的2G内存VPS直接进程killed，而使用了32G内存的物理机，在运行一段时间后，直接宕机。ミﾟДﾟ彡 awk后续使用了awk中的匹配功能，整体内存使用在1G左右，效率也高很多。 awk 'ARGIND==1 {a[$0]} ARGIND>1&amp;&amp;($3 in a) {print $0}' A B #ARGIND表示当前文件序号 #将A文件的$0赋值到数组a，如果B文件某行的$3有在数组a中出现，则打印该行； awk 'ARGIND==1 {a[$0]} ARGIND>1&amp;&amp;!($3 in a) {print $0}' A B #将A文件的$0赋值到数组a，如果B文件某行的$3没有在数组a中出现，则打印该行； 如此这般，awk的文本处理效率确实很高，使用方法十分灵活。好好学习这个吧~]]></content>
      <tags>
        <tag>LINUX</tag>
        <tag>shell</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux+Nginx+MariaDB+PHP_SERVER_BUILDING]]></title>
    <url>%2F2017%2F01%2F03%2FLinux-Nginx-MariaDB-PHP%2F</url>
    <content type="text"><![CDATA[Linux+Nginx+MariaDB+PHP,LNMP架构的动态网站服务器是比较流行的web服务器整体结构方案，由前几年比较流行的LAMP（Linux+Apache+Mysql+PHP）发展而来。其中将Apache替换成对硬件要求更低，并发数更高并且开源的Nginx；将被Oracle收购了的Mysql换成了完全兼容Mysql的MariaDB；其他不变。本次突发奇想决定玩一下PHP，所以在VPS上搭了个LNMP环境。 Linux选择VPS提供商镜像。KVM架构的VPS也可以自行安装各大Linux发行版。此处安装的是 # cat /etc/redhat-release CentOS release 6.6 (Final) # uname -a Linux LA 2.6.32-042stab113.21 #1 SMP Wed Mar 23 11:05:25 MSK 2016 i686 i686 i386 GNU/Linux NginxVPS提供的镜像的yum源的各个软件版本都较低，为了安装更新版的nginx，此处选择自行编译源码安装nginx。此处nginx安装参考这篇博客 需要首先安装gcc、gcc-c++、openssl此处选择简单的yum安装 yum install -y gcc gcc-c++ openssl 下载nginx源码和其所需的PCRE库与zlib库源码 mkdir nginx cd nginx wget http://nginx.org/download/nginx-1.8.1.tar.gz wget ftp://ftp.csx.cam.ac.uk/pub/software/programming/pcre/pcre-8.38.tar.gz wget https://ncu.dl.sourceforge.net/project/libpng/zlib/1.2.8/zlib-1.2.8.tar.gz tar zxvf nginx-1.8.1.tar.gz tar zxvf pcre-8.38.tar.gz tar zxvf zlib-1.2.8.tar.gz 编译安装nginx cd nginx-1.8.1 ./configure --prefix=/usr/local/nginx --sbin-path=/usr/local/nginx/nginx --conf-path=/usr/local/nginx/nginx.conf --pid-path=/usr/local/nginx/nginx.pid --with-http_ssl_module --with-pcre=../pcre-8.38 --with-zlib=../zlib-1.2.8 make make install 安装目录以及其他配置等目录可以自定义。--with-pcre=和--with-zlib=源码路径根据实际填写。直接启动/usr/local/nginx/nginx即可。 curl http://localhost &lt;!DOCTYPE html> &lt;html> &lt;head> &lt;title>Welcome to nginx!&lt;/title> ... ... 表示安装成功。如果未成功，请查看80端口是否占用，或者使用其他端口。/usr/local/nginx/nginx有一下几个参数选择，可自行研究。 Options: -?,-h : this help -v : show version and exit -V : show version and configure options then exit -t : test configuration and exit -q : suppress non-error messages during configuration testing -s signal : send signal to a master process: stop, quit, reopen, reload -p prefix : set prefix path (default: /usr/local/nginx/) -c filename : set configuration file (default: /usr/local/nginx/nginx.conf) -g directives : set global directives out of configuration file 可以在/etc/rc.local中添加开机启动 PHP此处MariaDB安装参考这篇博客下载PHP源码，解压。 wget http://cn2.php.net/distributions/php-7.1.0.tar.gz tar zxvf php-7.1.0.tar.gz 安装PHP的各类依赖包 yum -y install libxml2 libxml2-devel openssl openssl-devel curl curl-devel libjpeg install libjpeg-devel install libpng install libpng-devel install freetype install freetype-devel install pcre install pcre-devel install libxslt install libxslt-devel 编译安装 cd php-7.1.0 ./configure --prefix=/usr/local/php --with-curl --with-freetype-dir --with-gd --with-gettext --with-iconv-dir --with-kerberos --with-libdir=lib64 --with-libxml-dir --with-mysqli --with-openssl --with-pcre-regex --with-pdo-mysql --with-pdo-sqlite --with-pear --with-png-dir --with-jpeg-dir --with-xmlrpc --with-xsl --with-zlib --with-bz2 --with-mhash --enable-fpm --enable-bcmath --enable-libxml --enable-inline-optimization --enable-gd-native-ttf --enable-mbregex --enable-mbstring --enable-opcache --enable-pcntl --enable-shmop --enable-soap --enable-sockets --enable-sysvsem --enable-sysvshm --enable-xml --enable-zip make make install 注意编译时间较久。接下来配置PHP和nginx。首先从PHP源码目录中复制默认配置到相应目录 cp php.ini-development /usr/local/php/php.ini cp /usr/local/php/etc/php-fpm.conf.default /usr/local/php/etc/php-fpm.conf cp sapi/fpm/php-fpm /usr/local/bin 创建web用户 groupadd www-data useradd -g www-data www-data 修改php-fpm.conf中包含的php-fpm.d目录实际路径 vim /usr/local/php/etc/php-fpm.conf 修改其中包含配置的路径include=NONE/etc/php-fpm.d/*.conf为/usr/local/php/etc/php-fpm.d/下 cp /usr/local/php/etc/php-fpm.d/www.conf.default /usr/local/php/etc/php-fpm.d/www.conf vim /usr/local/php/etc/php-fpm.d/www.conf 添加用户名和用户组 user = www-data group = www-data 接下来修改nginx配置vim /usr/local/nginx/nginx.conf。修改nginx的运行用户和用户组为www-data：www-data。在server{}中的location / {}模块中加入index.php项，并删除释掉启动location ~* \.php$ {}模块，使php生效。修改fastcgi路径fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; user www-data www-data; ... ... location / { root html; index index.html index.htm index.php; } ... ... location ~ \.php$ { root html; fastcgi_pass 127.0.0.1:9000; fastcgi_index index.php; #fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; fastcgi_param SCRIPT_FILENAME $document_root$fastcgi_script_name; include fastcgi_params; } 启动nginx和php-fpm /usr/local/nginx/nginx -s restart /usr/local/bin/php-fpm 可通过查看php-fpm的9000端口是否在监听来判断php-fpm是否启动 # netstat -tln | grep 9000 tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN 接下里一般会在nginx的html目录下新建一个vim info.php来验证php能否正好解析。 &lt;?php phpinfo(); ?> 访问http://ip/info.php可以看到安装的php的版本和支持库之类的信息。 MariaDBMariaDB是Mysql的一个分支，目前还是完全兼容Mysql的，所以在安装的时候目录和名称依然采用mysql的名字。此处MariaDB安装参考这篇博客下载MariaDB源码，并解压 mkdir mariadb cd mariadb wget https://mirrors.tuna.tsinghua.edu.cn/mariadb//mariadb-10.1.20/source/mariadb-10.1.20.tar.gz tar zxvf mariadb-10.1.20.tar.gz yum安装MariaDB依赖包 yum -y install readline-devel zlib-devel openssl-devel libaio-devel 数据库设计到原始数据，所以一般需要新建专用的用户和用户来运行。这里新建mysql：mysql用户和用户组，并不允许ssh远程登录。 groupadd -r mysql #创建系统用户组 useradd -g mysql -s /sbin/nologin mysql #创建用户，归属于mysql组，不允许远程登录 接下来创建数据库目录，并更改为拥有者。此处将数据库数据存放在/data/mysql目录中。 mkdir -p /data/mysql chown -R mysql:mysql /data/mysql/ 现在可以安装MariaDB了。 cd mariadb-10.1.20 cmake . -DCMAKE_INSTALL_PREFIX=/usr/local/mysql -DMYSQL_DATADIR=/data/mysql -DSYSCONFDIR=/etc -DWITHOUT_TOKUDB=1 -DMYSQL_UNIX_ADDR=/tmp/mysql.sock -DDEFAULT_CHARSET=utf8 -DDEFAULT_COLLATION=utf8_general_ci make make install 此处编译时间较长，需要耐心等待，若出现编译失败的情况，请删除目录下的编译缓存文件CMakeCache.txt后，更改相关依赖关系重新编译。安装成功后，进入安装目录，初始化mysql服务器，并安装服务到系统服务中，设置开机启动服务。 cd /usr/local/mysql/ chown -R mysql:mysql * scripts/mysql_install_db --user=mysql cp support-files/mysql.server /etc/init.d/mysqld chkconfig --add mysqld # 添加至系统服务 chkconfig mysqld on # 设置开机自启动 最后将/var/lib/mysql/mysql.sock链接到/tmp/mysql.sock，否者无法进入mysql。启动mysql服务。 ln -s /var/lib/mysql/mysql.sock /tmp/mysql.sock service mysqld start 后续操作参考mysql入门教程。]]></content>
      <tags>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[nginx-rtmp流媒体服务器]]></title>
    <url>%2F2016%2F12%2F25%2Fnginx-rtmp%2F</url>
    <content type="text"><![CDATA[简介Nginx是http和反向代理服务器，同时支持邮件协议（IMAP/POP3/SMTP），由俄罗斯程序设计师Igor Sysoev所开发，其代码遵循BSD许可证开源。由于其轻量，占用系统资源少，并发量强的特点，而拥有不少的用户。Nginx-rtmp-module是nginx的一个模块，开源。使用这个模块开源在nginx的基础上快速搭建起一个流媒体服务器。配合ffmpeg开源项目开源实现许多点播和直播的基本功能。 功能特点Nginx-rtmp架构的流媒体服务器具有以下一些功能特点：（翻译自官网） 支持RTMP / HLS / MPEG-DASH协议的视频直播。测试推流可以实现rtmp 和http flv 的推流，hls和dash并没有测试推流；拉流可以实现rtmp 和hls，没有测试http flv 和dash。2.支持flv/mp4格式的视频点播，支持以文件或者http的方式的输入。3.支持两种流的分发模式 push and pull4.可以将多直播流分别录制成flv文件5.支持H264/AAC编码6.支持在线转码 Onlinetranscoding with FFmpeg 转码实现也是exec ffmpeg的，理论上支持一切ffmpeg支持的库。7.支持HLS (HTTP Live Streaming)需要 libavformat (&gt;= 8. 53.31.100) from ffmpeg (ffmpeg.org)8.支持http回调 HTTPcallbacks (publish/play/record/update etc)9.支持特定情况下调用外部程序(exec) ffmpeg转码即采用这种方式10.使用HTTPcontrol模块来 recording audio/video and dropping clients11.先进内存控制技术，可以在使用少量内存的情况下完成流畅的直播功能。12.可以和以下外部程序协同工作：Wirecast, FMS, Wowza, JWPlayer, FlowPlayer, StrobeMediaPlayback, ffmpeg, avconv, rtmpdump, flvstreamer等。13.统计数据展示在XML / XSL文件中，友好的可读形式。14.支持跨平台 Linux/FreeBSD/MacOS。 安装及配置以下针对nginx-rtmp服务器的安装以及一些配置项做一下简单介绍。 安装部署nginx-rtmp-module：wget -O nginx-rtmp-module.zip https://github.com/arut/nginx-rtmp-module/archive/master.zip unzip nginx-rtmp-module.zip nginx：wget http://nginx.org/download/nginx-1.11.6.tar.gz tar –x zxvf nginx-1.11.6.tar.gz 编译安装：部署nginx-rtmp服务器除了需要nginx本身的一些支撑包和库之外，在configure的时候需要添加nginx-rtmp-module选项。 ./configure --prefix=/usr/local/nginx --with-http_ssl_module --add-module=/root/nginx-rtmp-module make &amp;&amp; make install 配置原生的nginx-rtmp的所有功能均在nginx的配置文件/usr/local/nginx/conf/nginx.conf中实现。nginx.conf的整体架构： #rtmp配置 rtmp { server { listen 1935; chunk_size 4000 application app_name { ………… #配置项 } application app_name2 { ………… #配置项 } application vod { play /var/flvs; #video on demand } } } #nginx配置 http { server { location /hls { # Serve HLS fragments types { application/vnd.apple.mpegurl m3u8; video/mp2t ts; } root /tmp; add_header Cache-Control no-cache; } } } 需要在rtmp{ }中配置各种流媒体相关的配置，在http{ }中配置各种http相关的配置。各个application独立配置，支持正则匹配。以下介绍一些重要的配置项： 直播基本配置：rtmp推拉流在rtmp{ server{ * } }中配置以下内容 application mytv { live on; } 如此即配置了发布点为mytv 的直播频道，可以实现rtmp推流和拉流。推拉流地址： rtmp://ip:1935/mytv/stream hls在application mytv { * }中配置以下内容 application mytv { ………… #省略其他配置 hls on; hls_path /tmp/hls; hls_fragment 15s; } 在http { server{ location /hls { } } }中配置以下内容 http { ... server { ... location /hls { types { application/vnd.apple.mpegurl m3u8; } root /tmp; add_header Cache-Control no-cache; add_header Access-Control-Allow-Origin *; } } } 如此配置之后，这个即可进行hls拉流.详细的关于hls的其他配置。如切片时间命名设置、是否加密hls等配置可以参考：hls配置文档 MPEG-DASH在application配置段中配置： dash on; dash_path /tmp/dash; dash_fragment 15s; 在http配置段中配置： http { ... server { ... location /dash { root /tmp; add_header Cache-Control no-cache; # To avoid issues with cross-domain HTTP requests (e.g. during development) add_header Access-Control-Allow-Origin *; } } } MPEG-DASH 实现方式与HLS类似，具体可以查看：mpeg-dash配置文档 自动转推当多台nginx-rtmp 服务器运行时，可以配置把流自动推到其他机器上。 rtmp_auto_push on; rtmp_auto_push_reconnect 1s; rtmp_socket_dir /var/sock; rtmp { server { listen 1935; application myapp { live on; } } } 此功能没有测试过，未知其具体转推是如何实现的。 录制在application mytv { * }中配置以下内容 application mytv { ………… #省略其他配置 # record first 1K of stream record all; record_path /tmp/av; record_max_size 1K; # append current timestamp to each flv record_unique on; #开启后每个录制文件根据时间命名 } 其他录制选项可参考：record配置文档 转码nginx-rtmp 采用调用外部程序ffmpeg 进行转码。需要在application mytv { * }中配置以下内容 rtmp { server { listen 1935; application src { live on; exec ffmpeg -i rtmp://localhost/src/$name -c:a libfdk_aac -b:a 32k -c:v libx264 -b:v 128K -f flv rtmp://localhost/hls/$name_low -c:a libfdk_aac -b:a 64k -c:v libx264 -b:v 256k -f flv rtmp://localhost/hls/$name_mid -c:a libfdk_aac -b:a 128k -c:v libx264 -b:v 512K -f flv rtmp://localhost/hls/$name_hi; } application hls { live on; …… } } } exec ffmpeg 这样的配置是会在拉流请求转码流的时候触发ffmpeg 拉流转码，在多台机器做流媒体的时候，可以通过exec_pul 和exec_push 来配置在拉流时触发转码或者在推流时触发转码。 exec关于调用外部程序，nginx-rtmp 支持多个配置项，参考：exec配置文档 统计信息在http{ server{ } }中配置可以启用统计信息。 http { server { location /stat { rtmp_stat all; rtmp_stat_stylesheet stat.xsl; } location /stat.xsl { root /path/to/stat/xsl/file; } } } 访问http://192.168.1.1:8765/stat可以看到当前时间内的各个application 的概况。也可以下载http://192.168.1.1:8765/stat.xsl 进行统计。端口号根据nginx配置而定。 日志除了原生nginx 自带的error.log 和access.log 两个日志外，nginx-rtmp-module 模块还有一个rtmp-aceesss.log 日志。默认都是在nginx 的安装目录的 /logs 目录中。查阅资料后发现，nginx 应该是可以自定日志的格式的。在配置文件中也可以定义错误日志的级别，有debug | info | notice | warn | error | crit 几个级别，大概排查问题都利用debug 级别的错误日志。 控制模块nginx-rtmp 服务器支持以http的形式从外部对rtmp 进行控制。需要配置以下项。 http { …… server { listen 8080; server_name localhost; .... location /control { rtmp_control all; } } } 再在需要控制的application中预设好各种参数之后，便可以采用类似接口的形式对某些流进行录制，禁播，重定向之类的操作了。以下展示开始和停止录制的url。 curl &quot;http://localhost:8080/control/record/start?app=myapp&amp;name=mystream&amp;rec=rec1&quot; curl &quot;http://localhost:8080/control/record/stop?app=myapp&amp;name=mystream&amp;rec=rec1&quot; 具体的控制说明可以查看：control配置文档 总结Nginx-rtmp 架构的流媒体服务器实际测试基本功能都有，性能也不错。在配置较差的VPS 上搭建也可以流畅运行，并不占用太多的资源。但是其只能实现简单的功能，实际对于业务以及运营需要改进的地方还有很多。实测nginx-rtmp 服务器在hls 时，播放有时会有卡顿，原因未知；同码率推到其他流媒体服务器，hls 拉流没有卡顿，可能跟推流也有关系。 Q&amp;AsQ: mpeg dash？A: 类似于apple家的HLS，MPEG-DASH 是基于HTTP的自适应串流方案中的唯一国际标准。也是有小切片和索引文件组成，SC计划在明年支持此协议。 Q: http callback？A: 在nginx-rtmp 的官方wiki 中描述的http callback 大概意思为客户端发送连接请求时，会发送一个异步http 请求，会使处理暂停，直到返回状态码之后再根据状态码继续连接请求。具体可以查看：https://github.com/arut/nginx-rtmp-module/wiki/Directives#notify Q: 多域名配置？A: 网上资料说nginx 本身是可以改写url 的，有可以配置多个域名；nginx-rtmp 服务器没有说明可以支持多域名的配置，目测在做一些修改之后是可以做到支持多域名的。 Q: 延迟？A: nginx-rtmp 的拉流和推流，延迟在1s左右。在播放器缓冲设置在0时所测。]]></content>
      <tags>
        <tag>live</tag>
        <tag>LINUX</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MarkDown_Test]]></title>
    <url>%2F2016%2F11%2F12%2Fmarkdown_test%2F</url>
    <content type="text"><![CDATA[This a MarkDown test script. there are syntax code blow its markup effects. [TOC] HEADER:HEADER_1# HEADER_1 # HEADER_2## HEADER_2 ## HEADER_3### HEADER_3 ### HEADER_4#### HEADER_4 #### LIST:有序：1. a 1. aa 2. bb 1. aaa 2. aaa 3. cc 2. b 3. c 1. a 2. b 3. c 无序： a a.a a.a.a a.a.a.a a.a.a.b a.a.b a.b b - a - a.a * a.a.a + a.a.a.a - a.a.a.b - a.a.b - a.b - b note: ‘*‘ is equivalent to ‘-‘ &amp; ‘+‘. QUOTE: Ygritte: you know nothing，Jon Snow. Ygritte: you know nothing，Jon Snow. CODE:in a sentence：var is a variable. `var` is a variable. code block：var context = canvas.getContext("2d"); ```javascript var context = canvas.getContext(&quot;2d&quot;);``` TABLE: Tables Are Cool col 3 is right-aligned $1600 col 2 is centered $12 zebra stripes are neat $1 | Tables | Are | Cool | | ------------- |:-------------:| -----:| | col 3 is | right-aligned | $1600 | | col 2 is | centered | $12 | | zebra stripes | are neat | $1 | FORMAT:LETTER FORMAT:this is bold, and this is italic, this is delete-line. this is **bold**, and this is *italic*, this is ~~delete-line~~. HORIZONTAL LINE: --- *** TODO or ORDER LIST: Cmd Markdown 开发 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 支持以 PDF 格式导出文稿 新增Todo列表功能 语法参考 改进 LaTex 功能 修复 LaTex 公式渲染问题 新增 LaTex 公式编号功能 语法参考 七月旅行准备 准备邮轮上需要携带的物品 浏览日本免税店的物品 购买蓝宝石公主号七月一日的船票 - [ ] **Cmd Markdown 开发** - [ ] 改进 Cmd 渲染算法，使用局部渲染技术提高渲染效率 - [ ] 支持以 PDF 格式导出文稿 - [x] 新增Todo列表功能 [语法参考](https://github.com/blog/1375-task-lists-in-gfm-issues-pulls-comments) - [x] 改进 LaTex 功能 - [x] 修复 LaTex 公式渲染问题 - [x] 新增 LaTex 公式编号功能 [语法参考](http://docs.mathjax.org/en/latest/tex.html#tex-eq-numbers) - [ ] **七月旅行准备** - [ ] 准备邮轮上需要携带的物品 - [ ] 浏览日本免税店的物品 - [x] 购买蓝宝石公主号七月一日的船票 HYPERLINK:this is bing. this is [bing](https://www.bing.com/). IMAGE:this is the douban icon. ![Alt text](https://img3.doubanio.com/pics/douban-icons/favicon_48x48.png &quot;douban icon&quot;) others:it seems that HEXO does not support some MarkDown syntax, like flow-graph and sequence-graph. of course there are lots of features need to search.お互い顽张ろう ​ ​]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[test]]></title>
    <url>%2F2016%2F10%2F30%2Ftest%2F</url>
    <content type="text"><![CDATA[this is a comments test script. this is a comments test script. this is a comments test script.]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hello World]]></title>
    <url>%2F2016%2F10%2F03%2Fhello-world%2F</url>
    <content type="text"><![CDATA[Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post$ hexo new "My New Post" More info: Writing Run server$ hexo server More info: Server Generate static files$ hexo generate More info: Generating Deploy to remote sites$ hexo deploy More info: Deployment]]></content>
      <tags>
        <tag>test</tag>
      </tags>
  </entry>
</search>
